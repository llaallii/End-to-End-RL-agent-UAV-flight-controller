# Training hyperparameters for quadrotor hover with SAC.
# Requirement refs: RL007, RL008, RL009, RL011, RL012

algorithm: SAC  # SAC | PPO | TD3

# Environment
env_config_path: training/configs/hover_env.yaml

# Policy network (RL007: 2-layer MLP, 128 neurons, ReLU)
policy_kwargs:
  net_arch: [128, 128]    # Hidden layer sizes
  # activation_fn defaults to ReLU in SB3's MlpPolicy

# SAC hyperparameters
learning_rate: 3.0e-4
batch_size: 256
buffer_size: 100000
learning_starts: 1000      # Random exploration steps before training
gamma: 0.99                # Discount factor
tau: 0.005                 # Soft update coefficient
ent_coef: auto             # Automatic entropy tuning
train_freq: 1              # Update every step
gradient_steps: 1          # Gradient steps per update

# Training schedule
total_timesteps: 500000
seed: 42

# Evaluation
eval_freq: 10000           # Steps between evaluations
n_eval_episodes: 5         # Episodes per evaluation

# Checkpointing
checkpoint_freq: 50000     # Steps between checkpoint saves

# Logging
log_dir: training/logs
model_dir: training/models
tensorboard: true
wandb:
  enabled: false
  project: uav-hover-rl
  entity: null
